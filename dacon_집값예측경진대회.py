# -*- coding: utf-8 -*-
"""DACON_집값예측경진대회.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nHkZEJKoEzHE2ImXkY3XVqWeWoBn-5Qm
"""

import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder

# 다운받은 csv를 pandas의 DataFrame 형식으로 불러옵니다.
from google.colab import drive
drive.mount('/content/drive')
import pandas as pd
data=pd.read_csv('/content/drive/MyDrive/housing/train.csv',sep=',',encoding="cp949")
test=pd.read_csv('/content/drive/MyDrive/housing/test.csv',sep=',',encoding="cp949")

# id 는 제외하고 분석합니다.
data = data.drop('id', axis=1)
test = test.drop('id', axis=1)

data= data.drop_duplicates()#중복값제거
data.loc[254, 'Garage Yr Blt'] = 2007 #이상한값 변경

# 품질 관련 변수 → 숫자로 매핑
qual_cols = data.dtypes[data.dtypes == np.object].index
def label_encoder(df_, qual_cols):
  df = df_.copy()
  mapping={
      'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1
  }
  for col in qual_cols :
    df[col] = df[col].map(mapping)
  return df

data = label_encoder(data, qual_cols)
test = label_encoder(test, qual_cols)

#Feature Engineering
def feature_eng(data_):
  data = data_.copy()
  data['Overall Qual^2']=data['Overall Qual']*data['Overall Qual']
  data['base*1st']=data['Total Bsmt SF']*data['1st Flr SF']
  data['Gr Liv Area^2']=data['Gr Liv Area']*data['Gr Liv Area']
  data['Year Gap Remod'] = data['Year Remod/Add'] - data['Year Built']
  data['Car Area'] = data['Garage Area']/data['Garage Cars']
  data['2nd flr SF'] = data['Gr Liv Area'] - data['1st Flr SF']
  data['2nd flr'] = data['2nd flr SF'].apply(lambda x : 1 if x > 0 else 0)
  data['Total SF'] = data[['Gr Liv Area',"Garage Area", "Total Bsmt SF"]].sum(axis=1)
  data['Sum Qual'] = data[["Exter Qual", "Kitchen Qual", "Overall Qual"]].sum(axis=1)
  data['Garage InOut'] = data.apply(lambda x : 1 if x['Gr Liv Area'] != x['1st Flr SF'] else 0, axis=1)
  return data
train = feature_eng(data)
test = feature_eng(test)

#상관관계분석(Heatmap) 그리기
column_names = train.select_dtypes(exclude=['object']).columns
fig = plt.figure(figsize = (25,20))
sns.heatmap(train[column_names].corr(), annot = True)
plt.show() #0.8 이상

from sklearn.preprocessing import RobustScaler, OneHotEncoder
from sklearn.compose import make_column_transformer
from sklearn.pipeline import Pipeline

X, y = train.drop(columns="target"), train["target"]

scale_columns = ['Overall Qual', 'Gr Liv Area', 'Exter Qual', 'Garage Cars',
       'Kitchen Qual', 'Total Bsmt SF', '1st Flr SF',
       'Bsmt Qual', 'Full Bath','Year Remod/Add',
       'Garage Yr Blt', 'Overall Qual^2',
       'base*1st', 'Gr Liv Area^2', 'Car Area', 
       '2nd flr SF', '2nd flr', 'Total SF','Sum Qual', 'Garage InOut']

ct = make_column_transformer((RobustScaler(), scale_columns))

def get_pipe(model, model_name: str) -> Pipeline:
    pipe = Pipeline([
        ("ct", ct),
        (model_name, model)
    ])
    return pipe

# NMAE 평가 함수 만들기
from sklearn.metrics import make_scorer

def NMAE(true, pred) -> float:
    mae = np.mean(np.abs(true - pred))
    score = mae / np.mean(np.abs(true))
    return score

nmae_score = make_scorer(NMAE, greater_is_better=False)

from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, HistGradientBoostingRegressor

models = [
    ("gbr", GradientBoostingRegressor(random_state = 43, max_depth = 4, learning_rate = 0.03, n_estimators = 1000) ),
    ("rfr", RandomForestRegressor(random_state = 42, criterion = 'absolute_error')),
    ("hgb", HistGradientBoostingRegressor(random_state = 42, max_depth = 4, learning_rate = 0.03))
]

model_pipes = [(name, get_pipe(model, name)) for name, model in models]

#!pip install rich
import rich
from rich.table import Table
from tqdm.auto import tqdm
from sklearn.model_selection import cross_val_score

table = Table()
table.add_column("모델 이름", justify="left", style="green")
table.add_column("NMAE", justify="right")

for name, model in tqdm(model_pipes, leave=False):
    nmae_list = cross_val_score(model, X, y, scoring=nmae_score)
    nmae = -np.mean(nmae_list)
    table.add_row(name, f"{nmae:.4f}")

rich.print(table)

from sklearn.ensemble import StackingRegressor

stacking = StackingRegressor(model_pipes, n_jobs=-1)
nmae_list = cross_val_score(stacking, X, y, scoring=nmae_score)
nmae = -np.mean(nmae_list)
print(nmae)

stacking.fit(X, y)
stack_pred = stacking.predict(test)

sub=pd.read_csv('/content/drive/MyDrive/housing/sample_submission.csv',sep=',',encoding="cp949")
sub["target"] = stack_pred
sub.to_csv("submission.csv", index=False) 
